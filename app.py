import tkinter as tk
from tkinter import filedialog, messagebox
import cv2
import numpy as np
from collections import deque
import os
import time
import csv
import tempfile
from fpdf import FPDF
import threading
import matplotlib.pyplot as plt
import torch
import winsound
try:
    import ultralytics
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False

try:
    import beepy
    BEEP_AVAILABLE = True
except ImportError:
    BEEP_AVAILABLE = False

# å°å…¥å­æ¨¡çµ„
try:
    from ui import UIManager
except ImportError as e:
    print(f"å°å…¥UIæ¨¡çµ„å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿ui.pyæª”æ¡ˆèˆ‡app.pyåœ¨åŒä¸€ç›®éŒ„ä¸­")
    exit(1)

try:
    from data_processor import DataProcessor
except ImportError as e:
    print(f"å°å…¥è³‡æ–™è™•ç†æ¨¡çµ„å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿data_processor.pyæª”æ¡ˆèˆ‡app.pyåœ¨åŒä¸€ç›®éŒ„ä¸­")
    exit(1)

try:
    from video_processor import VideoProcessor
except ImportError as e:
    print(f"å°å…¥å½±ç‰‡è™•ç†æ¨¡çµ„å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿video_processor.pyæª”æ¡ˆèˆ‡app.pyåœ¨åŒä¸€ç›®éŒ„ä¸­")
    exit(1)

try:
    from resource_manager import ResourceManager
except ImportError as e:
    print(f"å°å…¥è³‡æºç®¡ç†æ¨¡çµ„å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿resource_manager.pyæª”æ¡ˆèˆ‡app.pyåœ¨åŒä¸€ç›®éŒ„ä¸­")
    exit(1)

class YOLOInferenceApp:
    def __init__(self, root):
        self.root = root
        self.is_monitoring = False
        self.root.title("YOLO å³æ™‚æ¨è«–ç³»çµ± - Material Area Detection (GPU Accelerated)")
        self.root.geometry("1700x950")
        self.root.configure(bg='#f0f0f0')
        
        # æª¢æŸ¥YOLOæ˜¯å¦å¯ç”¨
        if not YOLO_AVAILABLE:
            messagebox.showerror("éŒ¯èª¤", "è«‹å®‰è£ ultralytics: pip install ultralytics")
            return
        
        # åˆå§‹åŒ–å­æ¨¡çµ„
        self.resource_manager = ResourceManager(self)
        self.video_processor = VideoProcessor(self)
        self.ui_manager = UIManager(self)
        
        # GPU åˆå§‹åŒ–æª¢æŸ¥
        self.resource_manager.setup_gpu()
        
        # åˆå§‹åŒ–UIç®¡ç†å™¨
        self.ui_manager.setup_styles()
        
        # åˆå§‹åŒ–æ‰€æœ‰è®Šé‡
        self.model = None
        self.cap = None
        self.video_thread = None
        self.plot_update_thread = None
        self.monitor_thread = None
        self.is_inference = False  # å–ä»£åŸ is_runningï¼Œç‚ºæ¨è«–æ¨¡å¼
        self.is_preview = False     # æ–°å¢é è¦½æ¨¡å¼
        self.current_frame = None
        self.stream_type = "none"  # "video", "camera", "rtsp", "none"
        self.output_video_writer = None
        
        # é¢ç©è¨ˆç®—ç›¸é—œè®Šé‡
        self.raw_areas = []
        self.raw_time_stamps = []
        self.avg_areas = []
        self.avg_time_stamps = []
        self.sma_areas = []  # å¹³æ»‘å¾Œçš„é¢ç©æ•¸æ“š
        self.sma_time_stamps = []
        self.frame_group = []
        self.frame_times = []
        self.frame_count = 0
        self.last_detect_time = None
        self.video_fps = 30  # é è¨­FPS
        
        # å³æ™‚æ•¸æ“šé¡¯ç¤º
        self.recent_areas = deque(maxlen=100)
        self.recent_times = deque(maxlen=100)
        
        # åœ–è¡¨æ›´æ–°æ§åˆ¶
        self.last_plot_update = time.time()
        self.plot_update_interval = 1  # 1ç§’æ›´æ–°ä¸€æ¬¡
        
        # ç›£æ§æ§åˆ¶
        self.inference_start_time = None
        self.max_inference_time = 360 * 60  # 12åˆ†é˜
        self.max_no_detect_time = 60 * 60   # 5åˆ†é˜ç„¡æª¢æ¸¬
        
        # NG è¿½è¹¤
        self.ng_3_times = set()
        self.ng_5_times = set()
        
        # æ–°å¢ï¼šç›£æ§é–‹å§‹æ™‚çš„å½±åƒ
        self.start_monitor_image = None
        
        # è¨­å®šUI
        self.ui_manager.setup_ui()
        self.ui_manager.setup_initial_plot()
        self.load_model(silent=True)
    
    def update_confidence_label(self, value):
        """æ›´æ–°ä¿¡å¿ƒé–¾å€¼æ¨™ç±¤"""
        self.confidence_label.config(text=f"{float(value):.2f}")
    
    def update_fps_label(self, value):
        """æ›´æ–°FPSæ¨™ç±¤"""
        self.fps_label.config(text=f"{int(float(value))}")
    
    def load_model(self, silent=False):
        """è¼‰å…¥YOLOæ¨¡å‹ä¸¦é…ç½®GPU"""
        try:
            self.status_var.set("ğŸ”„ è¼‰å…¥æ¨¡å‹ä¸­...")
            self.system_info_var.set("æ­£åœ¨è¼‰å…¥AIæ¨¡å‹...")
            model_path = self.model_var.get()
            
            # æª¢æŸ¥è‡ªå®šç¾©æ¨¡å‹è·¯å¾‘æ˜¯å¦å­˜åœ¨
            if not model_path.endswith('.pt') or not any(model_path.endswith(std) for std in ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt']):
                if not os.path.exists(model_path):
                    raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}")
            
            # è¼‰å…¥æ¨¡å‹ä¸¦æŒ‡å®šè¨­å‚™
            self.model = YOLO(model_path)
            
            # é…ç½®æ¨¡å‹åˆ°GPU
            if self.gpu_available:
                self.model.to(device=self.device)
                # é ç†±GPU
                dummy_input = torch.randn(1, 3, 640, 640).to(self.device)
                with torch.no_grad():
                    _ = dummy_input * 2  # ç°¡å–®çš„GPUæ“ä½œä¾†é ç†±
                device_info = f"GPU-{self.device}"
            else:
                device_info = "CPU"
            
            model_name = model_path.split('\\')[-1] if '\\' in model_path else model_path
            self.status_var.set(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ ({device_info})")
            self.system_info_var.set(f"AIæ¨¡å‹å·²å°±ç·’: {model_name} ({device_info})")
            
            # æ›´æ–°GPUè¨˜æ†¶é«”è³‡è¨Š
            if self.gpu_available:
                self.memory_info_var.set(self.resource_manager.get_gpu_memory_info())
            
            if not silent:
                messagebox.showinfo("è¼‰å…¥æˆåŠŸ", f"YOLOæ¨¡å‹è¼‰å…¥æˆåŠŸï¼\né‹è¡Œè£ç½®: {device_info}")
                
        except Exception as e:
            self.status_var.set("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—")
            self.system_info_var.set("æ¨¡å‹è¼‰å…¥éŒ¯èª¤")
            messagebox.showerror("è¼‰å…¥éŒ¯èª¤", f"è¼‰å…¥æ¨¡å‹å¤±æ•—: {str(e)}")
    
    def on_model_change(self, event=None):
        """æ¨¡å‹é¸æ“‡æ”¹è®Šæ™‚çš„è™•ç†"""
        if self.is_inference:
            messagebox.showwarning("âš ï¸ è­¦å‘Š", "è«‹å…ˆåœæ­¢ç•¶å‰æ¨è«–å†æ›´æ›æ¨¡å‹")
            return
        self.load_model()
    
    def upload_video(self):
        """ä¸Šå‚³å½±ç‰‡æª”æ¡ˆ"""
        if self.is_inference or self.is_preview:
            messagebox.showwarning("âš ï¸ è­¦å‘Š", "è«‹å…ˆåœæ­¢ç•¶å‰æ“ä½œ")
            return
            
        file_path = filedialog.askopenfilename(
            title="é¸æ“‡å½±ç‰‡æª”æ¡ˆ",
            filetypes=[
                ("å½±ç‰‡æª”æ¡ˆ", "*.mp4 *.avi *.mov *.mkv *.wmv *.flv"),
                ("æ‰€æœ‰æª”æ¡ˆ", "*.*")
            ]
        )
        
        if file_path:
            try:
                # é‡‹æ”¾èˆŠçš„ VideoCapture è³‡æº
                if self.cap:
                    self.cap.release()
                    self.cap = None
                    print(f"[{time.strftime('%H:%M:%S', time.localtime())}] å·²é‡‹æ”¾èˆŠçš„ VideoCapture è³‡æº")
                
                # å˜—è©¦é–‹å•Ÿæ–°å½±ç‰‡
                self.cap = cv2.VideoCapture(file_path)
                if not self.cap.isOpened():
                    raise Exception(f"ç„¡æ³•é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ: {file_path} - å¯èƒ½æ ¼å¼ä¸æ”¯æ´æˆ–æª”æ¡ˆæå£")
                
                # ç²å–å½±ç‰‡å±¬æ€§
                self.video_fps = self.cap.get(cv2.CAP_PROP_FPS)
                if self.video_fps <= 0:
                    self.video_fps = 30  # é è¨­å€¼
                    print(f"[{time.strftime('%H:%M:%S', time.localtime())}] è­¦å‘Š: ç„¡æ³•ç²å–å½±ç‰‡FPSï¼Œé è¨­ç‚º {self.video_fps}")
                
                self.stream_type = "video"
                filename = os.path.basename(file_path)
                self.status_var.set(f"ğŸ“ å½±ç‰‡å·²è¼‰å…¥: {filename}")
                self.system_info_var.set(f"å½±ç‰‡ä¾†æº: {filename} (FPS: {self.video_fps:.1f})")
                print(f"[{time.strftime('%H:%M:%S', time.localtime())}] æˆåŠŸè¼‰å…¥å½±ç‰‡: {filename}")
                # å•Ÿå‹•é è¦½
                self.start_preview()
            except Exception as e:
                self.cap = None  # ç¢ºä¿ cap è¢«é‡ç½®
                messagebox.showerror("è¼‰å…¥éŒ¯èª¤", f"è¼‰å…¥å½±ç‰‡å¤±æ•—: {str(e)}")
                print(f"[{time.strftime('%H:%M:%S', time.localtime())}] éŒ¯èª¤ç´°ç¯€ - è¼‰å…¥å½±ç‰‡ {file_path}: {str(e)}")

    def open_camera(self):
        """é–‹å•Ÿæœ¬åœ°æ”åƒæ©Ÿ"""
        if self.is_inference or self.is_preview:
            messagebox.showwarning("âš ï¸ è­¦å‘Š", "è«‹å…ˆåœæ­¢ç•¶å‰æ“ä½œ")
            return
            
        try:
            camera_id = int(self.camera_id_var.get())
            if self.cap:
                self.cap.release()
            self.cap = cv2.VideoCapture(camera_id)
            if not self.cap.isOpened():
                raise Exception(f"ç„¡æ³•é–‹å•Ÿæ”åƒæ©Ÿ ID: {camera_id}")
            self.stream_type = "camera"
            self.status_var.set(f"ğŸ“· æœ¬åœ°æ”åƒæ©Ÿå·²é–‹å•Ÿ")
            self.system_info_var.set(f"æ”åƒæ©Ÿä¾†æº: æœ¬åœ°æ”åƒæ©Ÿ #{camera_id}")
            # å•Ÿå‹•é è¦½
            self.start_preview()
        except Exception as e:
            messagebox.showerror("é€£æ¥éŒ¯èª¤", f"é–‹å•Ÿæ”åƒæ©Ÿå¤±æ•—: {str(e)}")
    
    def open_rtsp_stream(self):
        """é–‹å•ŸRTSPä¸²æµ"""
        if self.is_inference or self.is_preview:
            messagebox.showwarning("âš ï¸ è­¦å‘Š", "è«‹å…ˆåœæ­¢ç•¶å‰æ“ä½œ")
            return
            
        try:
            rtsp_url = self.rtsp_url_var.get().strip()
            if not rtsp_url:
                raise Exception("è«‹è¼¸å…¥RTSP URL")
                
            if self.cap:
                self.cap.release()
                
            # è¨­å®šOpenCVåƒæ•¸ä»¥æé«˜RTSPä¸²æµç©©å®šæ€§
            self.cap = cv2.VideoCapture(rtsp_url)
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # æ¸›å°‘ç·©è¡å»¶é²
            self.cap.set(cv2.CAP_PROP_FPS, 30)  # è¨­å®šå¹€ç‡
            
            if not self.cap.isOpened():
                raise Exception("ç„¡æ³•é€£æ¥åˆ°RTSPä¸²æµï¼Œè«‹æª¢æŸ¥URLå’Œç¶²è·¯é€£ç·š")
                
            self.stream_type = "rtsp"
            self.status_var.set("ğŸŒ RTSPä¸²æµå·²é€£æ¥")
            self.system_info_var.set("ä¸²æµä¾†æº: RTSPç¶²è·¯æ”åƒæ©Ÿ")
            # å•Ÿå‹•é è¦½
            self.start_preview()
        except Exception as e:
            messagebox.showerror("é€£æ¥éŒ¯èª¤", f"é€£æ¥RTSPä¸²æµå¤±æ•—: {str(e)}")
    
    def start_preview(self):
        """å•Ÿå‹•å½±åƒé è¦½"""
        if not self.cap or not self.cap.isOpened():
            messagebox.showwarning("è­¦å‘Š", "ç„¡æœ‰æ•ˆçš„å½±ç‰‡ä¾†æºï¼Œç„¡æ³•å•Ÿå‹•é è¦½")
            return
        self.is_preview = True
        self.video_thread = threading.Thread(target=self.video_processor.process_video, daemon=True)
        self.video_thread.start()
        self.status_var.set("ğŸ“º é è¦½æ¨¡å¼åŸ·è¡Œä¸­...")
        self.system_info_var.set("å½±åƒé è¦½ä¸­ (ç„¡æ¨è«–)")
        self.memory_info_var.set(self.resource_manager.get_gpu_memory_info())
    
    def toggle_monitoring(self):
        """åˆ‡æ›ç›£æ§ç‹€æ…‹ä¸¦æ“·å–é–‹å§‹ç›£æ§æ™‚çš„å½±åƒ"""
        if not self.is_inference:
            messagebox.showwarning("âš ï¸ è­¦å‘Š", "è«‹å…ˆé–‹å§‹æ¨è«–å†å•Ÿå‹•ç›£æ§")
            return
        
        self.is_monitoring = not self.is_monitoring
        if self.is_monitoring:
            self.monitor_button.config(text="ğŸ›‘ åœæ­¢ç›£æ§")
            self.status_var.set("ğŸš¨ ç›£æ§å·²å•Ÿå‹•")
            # æ“·å–é–‹å§‹ç›£æ§æ™‚çš„å½±åƒ
            if self.current_frame is not None:
                self.start_monitor_image = self.current_frame.copy()
            else:
                print(f"[{time.strftime('%H:%M:%S', time.localtime())}] Warning: No current frame available for start monitor image")
        else:
            self.monitor_button.config(text="ğŸ” é–‹å§‹ç›£æ§")
            self.status_var.set("ğŸŸ¢ ç›£æ§å·²åœæ­¢")
            self.start_monitor_image = None
    
    def start_inference(self):
        """é–‹å§‹æ¨è«–"""
        if not self.model:
            messagebox.showerror("æ¨¡å‹éŒ¯èª¤", "è«‹å…ˆè¼‰å…¥YOLOæ¨¡å‹")
            return
            
        if not self.cap or not self.cap.isOpened():
            messagebox.showerror("ä¾†æºéŒ¯èª¤", "è«‹å…ˆé¸æ“‡å½±ç‰‡ä¾†æº")
            return
        
        # é‡ç½®è¨ˆæ•¸å™¨å’Œæ•¸æ“š
        self.reset_area_data()
        
        # æ¸…ç†GPUè¨˜æ†¶é«”
        if self.gpu_available:
            torch.cuda.empty_cache()
        
        # è¨­å®šè¼¸å‡ºå½±ç‰‡
        if self.save_output_var.get() and self.stream_type == "video":
            self.setup_output_video()
        
        self.is_inference = True
        self.inference_start_time = time.time()
        self.start_button.config(state=tk.DISABLED)
        self.stop_button.config(state=tk.NORMAL)
        self.clear_button.config(state=tk.DISABLED)
        
        # å¦‚æœé è¦½ä¸­ï¼Œç„¡éœ€é‡æ–°å•Ÿå‹•ç·šç¨‹ï¼Œç›´æ¥åˆ‡æ›æ¨¡å¼
        if self.video_thread is None or not self.video_thread.is_alive():
            self.video_thread = threading.Thread(target=self.video_processor.process_video, daemon=True)
            self.video_thread.start()
        
        # å•Ÿå‹•åœ–è¡¨æ›´æ–°ç·šç¨‹
        self.plot_update_thread = threading.Thread(target=self.plot_update_loop, daemon=True)
        self.plot_update_thread.start()
        
        # å•Ÿå‹•ç›£æ§ç·šç¨‹
        self.monitor_thread = threading.Thread(target=self.monitor_inference, daemon=True)
        self.monitor_thread.start()
        
        device_info = "GPU" if self.gpu_available else "CPU"
        self.status_var.set(f"ğŸš€ æ¨è«–åŸ·è¡Œä¸­... ({device_info})")
        self.system_info_var.set("AIæ¨¡å‹æ­£åœ¨åˆ†æä¸­...")
        self.memory_info_var.set(self.resource_manager.get_gpu_memory_info())
    
    def stop_inference(self):
        """åœæ­¢æ¨è«–ï¼Œåˆ‡æ›å›é è¦½æ¨¡å¼"""
        self.is_inference = False
        self.is_monitoring = False
        self.monitor_button.config(text="ğŸ” é–‹å§‹ç›£æ§")
        self.start_button.config(state=tk.NORMAL)
        self.stop_button.config(state=tk.DISABLED)
        self.clear_button.config(state=tk.NORMAL)
        
        # æ¸…ç†GPUè¨˜æ†¶é«”
        if self.gpu_available:
            torch.cuda.empty_cache()
        
        # é—œé–‰è¼¸å‡ºå½±ç‰‡
        if self.output_video_writer:
            self.output_video_writer.release()
            self.output_video_writer = None
        
        self.status_var.set("ğŸ“º é è¦½æ¨¡å¼")
        self.system_info_var.set("ç³»çµ±å¾…æ©Ÿä¸­ (é è¦½ç¹¼çºŒ)")
        self.fps_var.set("ğŸ¯ FPS: 0")
        self.runtime_var.set("â±ï¸ Runtime: 00:00")
        self.memory_info_var.set(self.resource_manager.get_gpu_memory_info())
        # ä¿æŒé è¦½æ¨¡å¼
        self.is_preview = True
    
    def stop_processing(self):
        """å®Œå…¨åœæ­¢æ‰€æœ‰è™•ç†ä¸¦é‡‹æ”¾è³‡æº"""
        self.is_inference = False
        self.is_preview = False
        self.is_monitoring = False
        if self.cap:
            self.cap.release()
            self.cap = None
        if self.output_video_writer:
            self.output_video_writer.release()
            self.output_video_writer = None
        
        # æ¸…ç†GPUè¨˜æ†¶é«”
        if self.gpu_available:
            torch.cuda.empty_cache()
            
        self.status_var.set("â¹ï¸ å·²åœæ­¢")
        self.system_info_var.set("ç³»çµ±å¾…æ©Ÿä¸­")
        self.fps_var.set("ğŸ¯ FPS: 0")
        self.runtime_var.set("â±ï¸ Runtime: 00:00")
        self.memory_info_var.set(self.resource_manager.get_gpu_memory_info())
    
    def clear_all_data(self):
        """æ¸…é™¤æ‰€æœ‰è³‡æ–™ä¸¦é‡ç½®ç³»çµ±"""
        if self.is_inference or self.is_preview:
            result = messagebox.askyesno("ç¢ºèªæ¸…é™¤", "ç³»çµ±æ­£åœ¨é‹è¡Œä¸­ï¼Œæ˜¯å¦è¦åœæ­¢ä¸¦æ¸…é™¤æ‰€æœ‰è³‡æ–™ï¼Ÿ")
            if not result:
                return
            self.stop_processing()
        
        try:
            # æ¸…é™¤æ‰€æœ‰æ•¸æ“š
            self.reset_area_data()
            
            # æ¸…ç†è³‡æº
            self.resource_manager.clear_memory_and_resources()
            
            # é‡ç½®UIé¡¯ç¤º
            self.current_area_var.set("ğŸ“ ç•¶å‰é¢ç©: --")
            self.avg_area_var.set("ğŸ“Š å¹³å‡é¢ç©: --") 
            self.sma_area_var.set("ğŸ“ˆ SMAé¢ç©: --")
            self.fps_var.set("ğŸ¯ FPS: 0")
            self.runtime_var.set("â±ï¸ Runtime: 00:00")
            
            # é‡ç½®åœ–è¡¨
            self.reset_sma_plot()
            
            # é‡ç½®å½±åƒé¡¯ç¤º
            self.image_label.configure(text="ğŸ¬ è«‹é¸æ“‡å½±ç‰‡ä¾†æºé–‹å§‹æª¢æ¸¬", image='')
            self.image_label.image = None
            
            self.status_var.set("ğŸŸ¡ è³‡æ–™å·²æ¸…é™¤ï¼Œç³»çµ±é‡ç½®å®Œæˆ")
            self.system_info_var.set("âœ… æ¸…é™¤å®Œæˆ")
            self.memory_info_var.set(self.resource_manager.get_gpu_memory_info())
            
            messagebox.showinfo("æ¸…é™¤å®Œæˆ", "æ‰€æœ‰è³‡æ–™å·²æ¸…é™¤ï¼Œç³»çµ±å·²é‡ç½®ï¼")
            
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"æ¸…é™¤è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    
    def reset_area_data(self):
        """é‡ç½®é¢ç©è¨ˆç®—æ•¸æ“š"""
        self.raw_areas = []
        self.raw_time_stamps = []
        self.avg_areas = []
        self.avg_time_stamps = []
        self.sma_areas = []
        self.sma_time_stamps = []
        self.frame_group = []
        self.frame_times = []
        self.frame_count = 0
        self.last_detect_time = None
        self.recent_areas.clear()
        self.recent_times.clear()
        self.last_plot_update = time.time()
        self.ng_3_times = set()
        self.ng_5_times = set()
        self.start_monitor_image = None
    
    def setup_output_video(self):
        """è¨­å®šè¼¸å‡ºå½±ç‰‡"""
        try:
            width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = self.video_fps
            
            output_path = filedialog.asksaveasfilename(
                title="å„²å­˜è¼¸å‡ºå½±ç‰‡",
                defaultextension=".mp4",
                filetypes=[("MP4 æª”æ¡ˆ", "*.mp4"), ("æ‰€æœ‰æª”æ¡ˆ", "*.*")]
            )
            
            if output_path:
                fourcc = cv2.VideoWriter_fourcc(*"mp4v")
                self.output_video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        except Exception as e:
            messagebox.showwarning("è¨­å®šè­¦å‘Š", f"è¨­å®šè¼¸å‡ºå½±ç‰‡å¤±æ•—: {str(e)}")
            self.save_output_var.set(False)
    
    def monitor_inference(self):
        """ç›£æ§æ¨è«–ç‹€æ…‹ï¼Œè‡ªå‹•é‡ç½®"""
        while self.is_inference:
            time.sleep(10)  # æ¯10ç§’æª¢æŸ¥ä¸€æ¬¡
            
            if not self.is_inference:
                break
                
            current_time = time.time()
            
            # æ›´æ–°GPUè¨˜æ†¶é«”è³‡è¨Š
            if self.gpu_available:
                self.root.after(0, lambda: self.memory_info_var.set(self.resource_manager.get_gpu_memory_info()))
            
            # æª¢æŸ¥ç¸½é‹è¡Œæ™‚é–“æ˜¯å¦è¶…é12åˆ†é˜
            if self.inference_start_time and (current_time - self.inference_start_time) > self.max_inference_time:
                print(f"[{time.strftime('%H:%M:%S', time.localtime())}] æ¨è«–æ™‚é–“è¶…é120åˆ†é˜ï¼Œè‡ªå‹•é‡ç½®...")
                self.root.after(0, self.auto_reset_system)
                break
            
            # æª¢æŸ¥æ˜¯å¦è¶…é5åˆ†é˜æ²’æœ‰æª¢æ¸¬åˆ°ç‰©ä»¶
            if self.last_detect_time and (current_time - self.last_detect_time) > self.max_no_detect_time:
                print(f"[{time.strftime('%H:%M:%S', time.localtime())}] è¶…é5åˆ†é˜ç„¡æª¢æ¸¬ï¼Œè‡ªå‹•é‡ç½®...")
                self.root.after(0, self.auto_reset_system)
                break
    
    def auto_reset_system(self):
        """è‡ªå‹•é‡ç½®ç³»çµ±ä¸¦é‡‹æ”¾è³‡æº"""
        self.stop_inference()
        self.resource_manager.clear_memory_and_resources()
        self.reset_sma_plot()
        self.status_var.set("ğŸ”„ ç³»çµ±è‡ªå‹•é‡ç½®: æª¢æ¸¬è¶…æ™‚")
        self.system_info_var.set("âš ï¸ è‡ªå‹•é‡ç½®å®Œæˆ")
        messagebox.showinfo("è‡ªå‹•é‡ç½®", "ç³»çµ±å·²è‡ªå‹•é‡ç½®\nåŸå› : 12åˆ†é˜é‹è¡Œè¶…æ™‚æˆ–5åˆ†é˜ç„¡æª¢æ¸¬")
    
    def reset_sma_plot(self):
        """é‡ç½®SMAåœ–è¡¨"""
        try:
            self.ax.clear()
            self.ui_manager.setup_initial_plot()
        except Exception as e:
            print(f"[{time.strftime('%H:%M:%S', time.localtime())}] é‡ç½®åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def plot_update_loop(self):
        """æ¯1ç§’æ›´æ–°ä¸€æ¬¡åœ–è¡¨çš„å¾ªç’°"""
        while self.is_inference:
            time.sleep(1)  # æ¯ç§’æª¢æŸ¥ä¸€æ¬¡
            current_time = time.time()
            
            if current_time - self.last_plot_update >= self.plot_update_interval:
                if len(self.sma_areas) > 0:
                    self.root.after(0, self.update_sma_plot)
                self.last_plot_update = current_time
    
    def update_sma_plot(self):
        """æ›´æ–°SMAé¢ç©è¶¨å‹¢åœ–"""
        try:
            self.ax.clear()
            
            # è¨­å®šåœ–è¡¨æ¨£å¼
            self.ax.set_facecolor('#fafafa')
            
            if len(self.sma_areas) > 0 and len(self.sma_time_stamps) > 0:
                # éæ¿¾æœ‰æ•ˆæ•¸æ“š
                valid_data = [(t, a) for t, a in zip(self.sma_time_stamps, self.sma_areas) if not np.isnan(a)]
                
                if valid_data:
                    times, areas = zip(*valid_data)
                    
                    # ç¹ªè£½SMAæ›²ç·š
                    self.ax.plot(times, areas, linewidth=3, color='#e74c3c', alpha=0.9, 
                               label=f'SMA Area (Window: {self.sma_window_var.get()})')
                    
                    # å¡«å……å€åŸŸ
                    self.ax.fill_between(times, areas, alpha=0.25, color='#e74c3c')
                    
                    # æ•¸æ“šé»æ¨™è¨˜
                    self.ax.scatter(times, areas, color='#c0392b', s=25, alpha=0.8, zorder=5)
                    
                    # æ¨™è¨»æœ€æ–°å€¼
                    if len(times) > 0:
                        latest_time, latest_area = times[-1], areas[-1]
                        self.ax.annotate(f'{latest_area:.0f} pxÂ²', 
                                       xy=(latest_time, latest_area), 
                                       xytext=(15, 15), textcoords='offset points',
                                       bbox=dict(boxstyle='round,pad=0.5', facecolor='#f1c40f', 
                                               edgecolor='#f39c12', alpha=0.9),
                                       fontsize=10, fontweight='bold', color='#2c3e50',
                                       arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.1', 
                                                     color='#f39c12', alpha=0.7))
                    
                    # çµ±è¨ˆè³‡è¨Š
                    mean_area = np.mean(areas)
                    std_area = np.std(areas)
                    max_area = np.max(areas)
                    min_area = np.min(areas)
                    
                    stats_text = f'ğŸ“ˆ Statistics\n'
                    stats_text += f'Mean: {mean_area:.0f} pxÂ²\n'
                    stats_text += f'Std: {std_area:.0f} pxÂ²\n'
                    stats_text += f'Max: {max_area:.0f} pxÂ²\n'
                    stats_text += f'Min: {min_area:.0f} pxÂ²'
                    
                    # æ·»åŠ GPUç‹€æ…‹
                    if self.gpu_available:
                        stats_text += f'\n\nğŸ”¥ GPU Accelerated'
                    
                    self.ax.text(0.02, 0.98, stats_text, transform=self.ax.transAxes, 
                               verticalalignment='top',
                               bbox=dict(boxstyle='round,pad=0.5', facecolor='white', 
                                       edgecolor='#bdc3c7', alpha=0.9),
                               fontsize=8, color='#2c3e50')
                    
                    # è¶¨å‹¢æŒ‡æ¨™
                    if len(areas) >= 2:
                        trend = "ğŸ“ˆ" if areas[-1] > areas[-2] else "ğŸ“‰" if areas[-1] < areas[-2] else "â¡ï¸"
                        trend_text = f"{trend} Trend"
                        self.ax.text(0.98, 0.98, trend_text, transform=self.ax.transAxes,
                                   verticalalignment='top', horizontalalignment='right',
                                   bbox=dict(boxstyle='round,pad=0.3', facecolor='#ecf0f1', alpha=0.8),
                                   fontsize=9, fontweight='bold')
                    
                    # æ¨™è¨˜NG
                    # æ¨™è¨˜é è­¦ (3åˆ†é˜ NG)
                    for t in self.ng_3_times:
                        self.ax.axvline(t, color='orange', linestyle='--', alpha=0.7)
                        self.ax.text(t, 600000 * 0.95, 'é è­¦', rotation=90, va='top', ha='right', color='orange', fontsize=8)
                    
                    # æ¨™è¨˜è­¦å ± (5åˆ†é˜ NG)
                    for t in self.ng_5_times:
                        self.ax.axvline(t, color='red', linestyle='-', alpha=0.8)
                        self.ax.text(t, 600000 * 0.9, 'è­¦å ±', rotation=90, va='top', ha='right', color='red', fontsize=8)
                        
                else:
                    # ç„¡æœ‰æ•ˆæ•¸æ“šæ™‚çš„é¡¯ç¤º
                    self.ax.text(0.5, 0.5, 'âš ï¸ No Valid Detection Data\nç­‰å¾…æª¢æ¸¬æ•¸æ“š...', 
                                transform=self.ax.transAxes, ha='center', va='center', 
                                fontsize=12, color='#e67e22',
                                bbox=dict(boxstyle='round,pad=0.8', facecolor='#ffeaa7', alpha=0.8))
            else:
                # ç„¡æ•¸æ“šæ™‚çš„é¡¯ç¤º
                init_text = 'â³ Initializing...\nç³»çµ±æº–å‚™ä¸­'
                if self.gpu_available:
                    init_text += '\nğŸ”¥ GPU Ready'
                
                self.ax.text(0.5, 0.5, init_text, 
                            transform=self.ax.transAxes, ha='center', va='center', 
                            fontsize=12, color='#74b9ff',
                            bbox=dict(boxstyle='round,pad=0.8', facecolor='#dde8fc', alpha=0.8))
            
            # è¨­å®šåœ–è¡¨æ¨™é¡Œå’Œæ¨™ç±¤
            title_text = 'ğŸ“Š SMA Area Trend Analysis\n(Real-time updates every 1s)'
            if self.gpu_available:
                title_text += ' - GPU Accelerated'
            
            self.ax.set_title(title_text, 
                             fontsize=12, fontweight='bold', color='#2c3e50', pad=20)
            self.ax.set_xlabel('Time (seconds)', fontsize=10, color='#34495e', fontweight='bold')
            self.ax.set_ylabel('Area (pxÂ²)', fontsize=10, color='#34495e', fontweight='bold')
            
            # è¨­å®šyè»¸ç¯„åœå’Œåˆ»åº¦
            self.ax.set_ylim(0, 600000)
            self.ax.set_yticks(np.arange(0, 600001, 50000))
            
            # ç¶²æ ¼å’Œæ¨£å¼
            self.ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.8, color='#bdc3c7')
            self.ax.spines['top'].set_visible(False)
            self.ax.spines['right'].set_visible(False)
            self.ax.spines['left'].set_color('#7f8c8d')
            self.ax.spines['bottom'].set_color('#7f8c8d')
            
            # åœ–ä¾‹è¨­å®š
            if len(self.sma_areas) > 0:
                valid_data = [(t, a) for t, a in zip(self.sma_time_stamps, self.sma_areas) if not np.isnan(a)]
                if valid_data:
                    self.ax.legend(loc='upper left', fontsize=9, framealpha=0.9, 
                                  fancybox=True, shadow=True)
            
            plt.tight_layout()
            self.canvas.draw()
            
        except Exception as e:
            print(f"[{time.strftime('%H:%M:%S', time.localtime())}] æ›´æ–°åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def check_and_handle_ng(self):
        """æª¢æŸ¥NGä¸¦è™•ç†è­¦å ±"""
        cleaned_areas = DataProcessor.clean_data(self.sma_areas, self.sma_time_stamps, gap_limit=3)
        results_3 = DataProcessor.check_area_trend_timebased(cleaned_areas, self.sma_time_stamps, minutes=3, epsilon=0.15, cooldown=180)
        results_5 = DataProcessor.check_area_trend_timebased(cleaned_areas, self.sma_time_stamps, minutes=4, epsilon=0.05, cooldown=210)
        ng_3 = DataProcessor.extract_ng_markers(results_3)
        ng_5 = DataProcessor.extract_ng_markers(results_5)
        
        # æ›´æ–°NGé›†åˆ
        self.ng_3_times.update(ng_3)
        new_ng_5 = set(ng_5) - self.ng_5_times
        self.ng_5_times.update(ng_5)
        
        # è™•ç†æ–°5åˆ†é˜è­¦å ±
        for t in new_ng_5:
            # å¯«å…¥ log CSV (ä½¿ç”¨å›ºå®šæª”æ¡ˆåç¨± 'ng_log.csv')
            start_str = time.strftime("%Y%m%d%H%M", time.localtime(self.inference_start_time))
            ng_str = time.strftime("%Y%m%d%H%M", time.localtime(self.inference_start_time + t))
            range_str = f"{start_str}-{ng_str}"
            duration = 5 * 60
            log_file = 'ng_log.csv'
            file_exists = os.path.exists(log_file) and os.path.getsize(log_file) > 0
            with open(log_file, 'a', newline='') as f:
                writer = csv.writer(f)
                if not file_exists:
                    writer.writerow(['Time Range', 'Duration (seconds)'])
                writer.writerow([range_str, duration])
            
            # é¡¯ç¤ºéæ¨¡æ…‹è­¦å‘Šè¦–çª—ä¸¦ç”ŸæˆPDF
            self.root.after(0, lambda rs=range_str: self.show_non_modal_warning(rs))
    
    def play_beep(self):
        """åœ¨ç¨ç«‹åŸ·è¡Œç·’ä¸­æ’­æ”¾èœ‚é³´è²"""
        winsound.Beep(2500, 5000)

    def show_non_modal_warning(self, range_str):
        """é¡¯ç¤ºéæ¨¡æ…‹è­¦å‘Šè¦–çª—ï¼Œè§¸ç™¼èœ‚é³´è²å’ŒPDFç”Ÿæˆ"""
        # æ’­æ”¾èœ‚é³´è²
        threading.Thread(target=self.play_beep, daemon=True).start()
        
        # ç²å–NGæ™‚çš„å½±åƒ
        ng_image = None
        if self.current_frame is not None:
            ng_image = self.current_frame.copy()
        else:
            print(f"[{time.strftime('%H:%M:%S', time.localtime())}] Warning: No current frame available for NG image")
        
        # ç”ŸæˆPDFï¼ˆå¦‚æœæœ‰é–‹å§‹ç›£æ§å½±åƒå’ŒNGå½±åƒï¼‰
        if self.start_monitor_image is not None and ng_image is not None:
            self.generate_pdf(range_str, self.start_monitor_image, ng_image)
        else:
            print(f"[{time.strftime('%H:%M:%S', time.localtime())}] Warning: Missing images for PDF generation")
        
        # é¡¯ç¤ºè­¦å‘Šè¦–çª—
        warning_win = tk.Toplevel(self.root)
        warning_win.title("è­¦å ±")
        warning_win.geometry("300x150")
        warning_win.attributes('-topmost', True)  # ç½®é ‚é¡¯ç¤º
        warning_win.configure(bg='#f0f0f0')  # ç°è‰²èƒŒæ™¯
        
        label = tk.Label(warning_win, text="å·²ç™¼ç”Ÿæ¶æ©‹ç¾è±¡,è«‹ç«‹å³åšè™•ç†", font=('Microsoft JhengHei UI', 12), bg='#f0f0f0', fg='#2c3e50')
        label.pack(expand=True, pady=20)
        
        close_button = tk.Button(warning_win, text="é—œé–‰", command=warning_win.destroy)
        close_button.pack(pady=10)
    
    def generate_pdf(self, range_str, img1, img2):
        """ä½¿ç”¨FPDFç”ŸæˆåŒ…å«å…©å¼µå½±åƒçš„PDFï¼Œå„ªåŒ–è‡¨æ™‚æª”æ¡ˆç®¡ç†"""
        pdf_filename = f"{range_str}.pdf"
        
        # ä½¿ç”¨è‡¨æ™‚æª”æ¡ˆä¾†å„²å­˜å½±åƒ
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_img1, \
             tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_img2:
            
            # å„²å­˜å½±åƒåˆ°è‡¨æ™‚æª”æ¡ˆ
            cv2.imwrite(temp_img1.name, img1)
            cv2.imwrite(temp_img2.name, img2)
            
            # å»ºç«‹PDF
            pdf = FPDF()
            pdf.add_page()
            
            # æ·»åŠ å½±åƒåˆ°PDF
            pdf.image(temp_img1.name, x=10, y=10, w=190, h=100)
            pdf.image(temp_img2.name, x=10, y=120, w=190, h=100)
            
            # å„²å­˜PDF
            pdf.output(pdf_filename)
        
        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        os.remove(temp_img1.name)
        os.remove(temp_img2.name)
        
        print(f"[{time.strftime('%H:%M:%S', time.localtime())}] PDF å·²ç”Ÿæˆ: {pdf_filename}")

def main():
    root = tk.Tk()
    app = YOLOInferenceApp(root)
    root.protocol("WM_DELETE_WINDOW", app.resource_manager.on_closing)
    root.mainloop()

if __name__ == "__main__":
    main()