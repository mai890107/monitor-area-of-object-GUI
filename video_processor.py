import cv2
import numpy as np
import pandas as pd
from PIL import Image, ImageTk
import threading
import time
import torch

class VideoProcessor:
    def __init__(self, app):
        self.app = app

    def process_video(self):
        """è™•ç†å½±åƒçš„ä¸»å¾ªç’°ï¼Œæ”¯æŒé è¦½å’Œæ¨è«–æ¨¡å¼ï¼ˆåŸºæœ¬GPUæ”¯æ´ï¼‰"""
        fps_counter = 0
        fps_start_time = time.time()
        consecutive_failures = 0
        max_failures = 10
        
        conf_thres = self.app.confidence_var.get()
        nan_gap = self.app.nan_gap_var.get()
        
        while (self.app.is_inference or self.app.is_preview) and self.app.cap and self.app.cap.isOpened():
            ret, frame = self.app.cap.read()
            
            if not ret:
                consecutive_failures += 1
                if self.app.stream_type == "rtsp" and consecutive_failures < max_failures:
                    time.sleep(0.5)
                    continue
                else:
                    break
            
            consecutive_failures = 0
            
            try:
                # æ›´æ–°é‹è¡Œæ™‚é–“ (åƒ…æ¨è«–æ¨¡å¼)
                if self.app.is_inference and self.app.inference_start_time:
                    runtime = int(time.time() - self.app.inference_start_time)
                    minutes, seconds = divmod(runtime, 60)
                    self.app.root.after(0, lambda: self.app.runtime_var.set(f"â±ï¸ Runtime: {minutes:02d}:{seconds:02d}"))
                
                # ä½¿ç”¨å¯¦éš›ç¶“éæ™‚é–“ä½œç‚ºæ™‚é–“æˆ³
                time_sec = time.time() - (self.app.inference_start_time if self.app.is_inference else time.time())
                
                annotated_frame = frame.copy()
                detected = False
                current_areas = []
                
                # å„²å­˜ç•¶å‰å¹€ä»¥ä¾›ç›£æ§ä½¿ç”¨
                self.app.current_frame = frame.copy()
                
                if self.app.is_inference:
                    # YOLOæ¨è«–ï¼ˆä½¿ç”¨GPUï¼‰
                    with torch.no_grad():  # ç¯€çœGPUè¨˜æ†¶é«”
                        results = self.app.model.predict(
                            frame, 
                            verbose=False, 
                            conf=conf_thres,
                            device=self.app.device,  # æŒ‡å®šä½¿ç”¨GPU
                            half=self.app.gpu_available  # å¦‚æœæœ‰GPUå‰‡ä½¿ç”¨åŠç²¾åº¦é‹ç®—
                        )[0]
                    
                    self.app.frame_group.append(results.boxes)
                    self.app.frame_times.append(time_sec)
                    
                    # è™•ç†æª¢æ¸¬çµæœä¸¦è¨ˆç®—é¢ç©
                    if results.boxes is not None and len(results.boxes) > 0:
                        for box in results.boxes:
                            conf = box.conf.item()
                            cls_id = int(box.cls.item())
                            if cls_id == 0 and conf > conf_thres:
                                x1, y1, x2, y2 = box.xyxy[0].tolist()
                                area = (x2 - x1) * (y2 - y1)
                                current_areas.append(area)
                                detected = True
                    
                    # è¨˜éŒ„åŸå§‹é¢ç©æ•¸æ“š
                    if detected:
                        total_area = sum(current_areas)
                        self.app.raw_areas.append(total_area)
                        self.app.raw_time_stamps.append(time_sec)
                        self.app.recent_areas.append(total_area)
                        self.app.recent_times.append(time_sec)
                        self.app.last_detect_time = time.time()
                        
                        # æ›´æ–°UIé¡¯ç¤º
                        self.app.root.after(0, lambda: self.app.current_area_var.set(f"ğŸ“ ç•¶å‰é¢ç©: {total_area:.0f} pxÂ²"))
                    elif self.app.last_detect_time is not None and time_sec - (self.app.last_detect_time - self.app.inference_start_time) > nan_gap:
                        self.app.raw_areas.append(np.nan)
                        self.app.raw_time_stamps.append(time_sec)
                        self.app.recent_areas.append(np.nan)
                        self.app.recent_times.append(time_sec)
                    
                    # æ¯2å¹€è¨ˆç®—å¹³å‡é¢ç©
                    if len(self.app.frame_group) == 2:
                        group_time = np.mean(self.app.frame_times) if self.app.frame_times else time_sec
                        self.calculate_average_area_with_sma(group_time, conf_thres, nan_gap)
                        self.app.frame_group = []
                        self.app.frame_times = []
                    
                    # ç¹ªè£½æª¢æ¸¬çµæœ
                    annotated_frame = results.plot()
                    
                    # åœ¨å½±åƒä¸Šé¡¯ç¤ºé¢ç©è³‡è¨Š
                    if detected:
                        # ä¸»è¦é¢ç©è³‡è¨ŠèƒŒæ™¯
                        cv2.rectangle(annotated_frame, (8, 8), (400, 90), (0, 0, 0), -1)  # é»‘è‰²èƒŒæ™¯
                        cv2.rectangle(annotated_frame, (8, 8), (400, 90), (0, 255, 255), 2)  # é»ƒè‰²é‚Šæ¡†
                        
                        cv2.putText(annotated_frame, f"Total Area: {sum(current_areas):.0f} px", 
                                  (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                        
                        # SMAé¢ç©è³‡è¨Š
                        if len(self.app.sma_areas) > 0:
                            latest_sma = self.app.sma_areas[-1]
                            if not np.isnan(latest_sma):
                                cv2.putText(annotated_frame, f"SMA Area: {latest_sma:.0f} px", 
                                          (15, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 100, 100), 2)
                        
                        # æª¢æ¸¬æ•¸é‡å’Œä¿¡å¿ƒåº¦
                        cv2.putText(annotated_frame, f"Objects: {len(current_areas)} | Conf: {conf_thres:.2f}", 
                                  (15, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                    
                    # GPUç‹€æ…‹é¡¯ç¤º
                    if self.app.gpu_available:
                        cv2.putText(annotated_frame, f"GPU Mode - Device: {self.app.device}", 
                                  (15, annotated_frame.shape[0] - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                    
                    # å„²å­˜è¼¸å‡ºå½±ç‰‡
                    if self.app.output_video_writer:
                        self.app.output_video_writer.write(annotated_frame)
                else:
                    # é è¦½æ¨¡å¼ï¼Œæ·»åŠ æ–‡å­—æç¤º
                    device_text = f"Preview Mode (No Inference) - {('GPU' if self.app.gpu_available else 'CPU')} Ready"
                    cv2.putText(annotated_frame, device_text, (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # è½‰æ›ä¸¦é¡¯ç¤ºå½±åƒ
                rgb_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(rgb_frame)
                
                # å‹•æ…‹èª¿æ•´é¡¯ç¤ºå°ºå¯¸
                label_width = self.app.image_label.winfo_width()
                label_height = self.app.image_label.winfo_height()
                
                if label_width > 100 and label_height > 100:
                    img_ratio = pil_image.width / pil_image.height
                    container_ratio = label_width / label_height
                    
                    if container_ratio > img_ratio:
                        new_height = min(label_height - 20, 600)
                        new_width = int(new_height * img_ratio)
                    else:
                        new_width = min(label_width - 20, 800)
                        new_height = int(new_width / img_ratio)
                    
                    display_size = (max(new_width, 480), max(new_height, 360))
                else:
                    display_size = (640, 480)
                
                pil_image = pil_image.resize(display_size, Image.Resampling.LANCZOS)
                tk_image = ImageTk.PhotoImage(pil_image)
                
                self.app.root.after(0, self.update_image_display, tk_image)
                
                # è¨ˆç®—FPS
                fps_counter += 1
                if time.time() - fps_start_time >= 1.0:
                    fps = fps_counter / (time.time() - fps_start_time)
                    self.app.root.after(0, lambda: self.app.fps_var.set(f"ğŸ¯ FPS: {fps:.1f}"))
                    fps_counter = 0
                    fps_start_time = time.time()
                
                self.app.frame_count += 1
                
                # èª¿æ•´è™•ç†é€Ÿåº¦
                time.sleep(1 / self.app.inference_fps_var.get())
                
                # å®šæœŸæ¸…ç†GPUè¨˜æ†¶é«”
                if self.app.gpu_available and self.app.frame_count % 100 == 0:
                    torch.cuda.empty_cache()
                    
            except Exception as e:
                print(f"è™•ç†å½±æ ¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                self.app.root.after(0, lambda: self.app.system_info_var.set(f"âŒ è™•ç†éŒ¯èª¤: {str(e)[:30]}..."))
                break
        
        # æ¸…ç†è³‡æº
        self.app.stop_processing()

    def calculate_average_area_with_sma(self, group_time, conf_thres, nan_gap):
        """è¨ˆç®—2å¹€çš„å¹³å‡é¢ç©ä¸¦æ‡‰ç”¨SMAå¹³æ»‘è™•ç†"""
        total_area, count = 0, 0
        
        for boxes in self.app.frame_group:
            if boxes is None or len(boxes) == 0:
                continue
            for box in boxes:
                conf = box.conf.item()
                cls_id = int(box.cls.item())
                if cls_id == 0 and conf > conf_thres:
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    area = (x2 - x1) * (y2 - y1)
                    total_area += area
                    count += 1
        
        if count > 0:
            avg_area = total_area / count
            self.app.avg_areas.append(avg_area)
            self.app.avg_time_stamps.append(group_time)
            self.app.last_detect_time = time.time()
            
            # æ‡‰ç”¨SMAå¹³æ»‘è™•ç†
            if len(self.app.avg_areas) >= 1:
                window_size = self.app.sma_window_var.get()
                # ä½¿ç”¨pandasé€²è¡Œç§»å‹•å¹³å‡å¹³æ»‘
                smoothed = pd.Series(self.app.avg_areas).rolling(window=window_size, min_periods=1).mean()
                self.app.sma_areas = smoothed.tolist()
                self.app.sma_time_stamps = self.app.avg_time_stamps.copy()
                
                # æ›´æ–°UIé¡¯ç¤º
                latest_sma = self.app.sma_areas[-1]
                overall_avg = np.nanmean(self.app.avg_areas) if self.app.avg_areas else 0
                self.app.root.after(0, lambda: self.app.avg_area_var.set(f"ğŸ“Š å¹³å‡é¢ç©: {overall_avg:.0f} pxÂ²"))
                self.app.root.after(0, lambda: self.app.sma_area_var.set(f"ğŸ“ˆ SMAé¢ç©: {latest_sma:.0f} pxÂ²"))
            
            # å¦‚æœç›£æ§å•Ÿå‹•ï¼Œç«‹å³æª¢æŸ¥NGä¸¦è™•ç†è­¦å ±
            if self.app.is_monitoring:
                self.app.root.after(0, self.app.check_and_handle_ng)
        else:
            if self.app.last_detect_time is not None and group_time - (self.app.last_detect_time - self.app.inference_start_time) > nan_gap:
                self.app.avg_areas.append(np.nan)
                self.app.avg_time_stamps.append(group_time)

    def update_image_display(self, tk_image):
        """æ›´æ–°å½±åƒé¡¯ç¤º"""
        self.app.image_label.configure(image=tk_image, text="")
        self.app.image_label.image = tk_image  # ä¿æŒå¼•ç”¨é¿å…è¢«åƒåœ¾å›æ”¶